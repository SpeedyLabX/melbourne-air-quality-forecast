{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b66650",
   "metadata": {},
   "source": [
    "# Melbourne Weather Historical Data Collection (HOURLY)\n",
    "# Research Notebook for Environmental Analysis - Raw Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa209bf",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook's **sole responsibility** is to fetch raw, high-resolution **hourly** historical weather data from the Open-Meteo API. It targets 23 monitoring locations across Melbourne, creating a foundational dataset for subsequent processing and analysis.\n",
    "\n",
    "### Key Features:\n",
    "- **Single Responsibility**: Focuses exclusively on ingesting raw hourly data.\n",
    "- **High-Quality Source**: Utilizes the Open-Meteo API for comprehensive historical weather data.\n",
    "- **Robust Retry Logic**: Automatically handles API rate limits (HTTP 429) to ensure complete data collection.\n",
    "- **Clean Raw Output**: Saves all data into a single, clean hourly CSV file, preserving the highest level of detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e720916",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754bd7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:32:57,811 - INFO - üå¶Ô∏è Melbourne HOURLY Weather Data Collection System (Open-Meteo)\n",
      "2025-06-20 23:32:57,814 - INFO - ============================================================\n",
      "2025-06-20 23:32:57,814 - INFO - üî¨ Research Environment Initialized\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: SETUP, IMPORTS, AND LOGGER CONFIGURATION\n",
    "# =============================================================================\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. UTF-8 Aware Logger Setup ---\n",
    "def setup_logger(log_file='logs/02_weather_melbourne_data_collection.log', level=logging.INFO):\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(level)\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    \n",
    "    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "# --- 2. Initialize Environment ---\n",
    "logger = setup_logger()\n",
    "logger.info(\"üå¶Ô∏è Melbourne HOURLY Weather Data Collection System (Open-Meteo)\")\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(\"üî¨ Research Environment Initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b2a8e",
   "metadata": {},
   "source": [
    "## 2. Configuration and Research Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391fb3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:32:57,860 - INFO - üéØ Weather Research Configuration Loaded\n",
      "2025-06-20 23:32:57,861 - INFO - üíæ Raw hourly data will be saved to: ../../data/raw/melbourne_raw_weather_openmeteo_2020-11-25_to_2025-01-04.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: RESEARCH CONFIGURATION FOR HOURLY WEATHER DATA\n",
    "# =============================================================================\n",
    "\n",
    "class WeatherDataConfig:\n",
    "    def __init__(self):\n",
    "        self.BASE_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        self.START_DATE = \"2020-11-25\"\n",
    "        self.END_DATE = \"2025-01-04\"\n",
    "        self.REQUEST_TIMEOUT = 60\n",
    "        \n",
    "        # The output is now clearly marked as 'hourly'\n",
    "        self.OUTPUT_CSV_PATH = f\"../../data/raw/melbourne_raw_weather_openmeteo_{self.START_DATE}_to_{self.END_DATE}.csv\"\n",
    "        \n",
    "        self.MONITORING_LOCATIONS = {\n",
    "            \"Melbourne CBD\": [-37.8136, 144.9631], \n",
    "            \"Footscray\": [-37.7997, 144.9020],\n",
    "            \"Brooklyn\": [-37.8161, 144.8415], \n",
    "            \"Alphington\": [-37.7833, 145.0333],\n",
    "            \"Spotswood\": [-37.8335, 144.8863], \n",
    "            \"Box Hill\": [-37.8185, 145.1225],\n",
    "            \"Brighton\": [-37.9056, 145.0028], \n",
    "            \"Dandenong\": [-37.9875, 145.2149],\n",
    "            \"Mooroolbark\": [-37.7825, 145.3168], \n",
    "            \"Altona North\": [-37.8410, 144.8490],\n",
    "            \"Melton\": [-37.6833, 144.5833], \n",
    "            \"Point Cook\": [-37.9148, 144.7509],\n",
    "            \"Macleod\": [-37.7333, 145.0667], \n",
    "            \"Carlton\": [-37.8001, 144.9656],\n",
    "            \"Richmond\": [-37.8183, 145.0014], \n",
    "            \"St Kilda\": [-37.8676, 144.9801],\n",
    "            \"Yarraville\": [-37.8167, 144.9000], \n",
    "            \"Frankston\": [-38.1421, 145.1256],\n",
    "            \"Ringwood\": [-37.8136, 145.2306], \n",
    "            \"Werribee\": [-37.9009, 144.6590],\n",
    "            \"Craigieburn\": [-37.5986, 144.9425], \n",
    "            \"Pakenham\": [-38.0753, 145.4834],\n",
    "            \"Broadmeadows\": [-37.6839, 144.9169],\n",
    "        }\n",
    "\n",
    "# --- Initialize configuration ---\n",
    "try:\n",
    "    config = WeatherDataConfig()\n",
    "    logger.info(f\"üéØ Weather Research Configuration Loaded\")\n",
    "    logger.info(f\"üíæ Raw hourly data will be saved to: {config.OUTPUT_CSV_PATH}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Could not initialize configuration: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a33d39",
   "metadata": {},
   "source": [
    "## 3. Data Collection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e95d40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:32:57,945 - INFO - üîß Hourly weather data collector class defined and instance created.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: CORE HOURLY DATA COLLECTION CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class WeatherDataCollector:\n",
    "    \"\"\"Handles fetching and saving raw hourly weather data from Open-Meteo.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: WeatherDataConfig):\n",
    "        self.config = config\n",
    "        self.session = requests.Session()\n",
    "        self.all_hourly_dataframes = [] # A list to hold DataFrames for each location\n",
    "        self.failed_locations = []\n",
    "\n",
    "    def fetch_for_location(self, location: str, lat: float, lon: float):\n",
    "        \"\"\"Fetches and processes data for a single location, adding it to the main list.\"\"\"\n",
    "        params = {\n",
    "            \"latitude\": lat, \"longitude\": lon,\n",
    "            \"start_date\": self.config.START_DATE, \"end_date\": self.config.END_DATE,\n",
    "            \"hourly\": \"temperature_2m,relative_humidity_2m,precipitation,surface_pressure,wind_speed_10m\",\n",
    "            \"timezone\": \"Australia/Melbourne\"\n",
    "        }\n",
    "        max_retries = 5\n",
    "        base_backoff_seconds = 5\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.session.get(self.config.BASE_URL, params=params, timeout=self.config.REQUEST_TIMEOUT)\n",
    "                if response.status_code == 429:\n",
    "                    wait_time = base_backoff_seconds * (2 ** attempt) + (os.urandom(1)[0] / 255.0)\n",
    "                    logger.warning(f\"üö¶ Rate limit for {location}. Retrying in {wait_time:.1f}s... (Attempt {attempt + 1}/{max_retries})\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                response.raise_for_status()\n",
    "\n",
    "                data = response.json()\n",
    "                df = pd.DataFrame(data['hourly'])\n",
    "                df['location'] = location\n",
    "                self.all_hourly_dataframes.append(df)\n",
    "                logger.info(f\"‚úÖ Fetched {len(df)} hourly records for {location}.\")\n",
    "                return\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logger.error(f\"‚ùå Request failed for {location} on attempt {attempt + 1}: {e}\")\n",
    "                time.sleep(base_backoff_seconds)\n",
    "\n",
    "        logger.error(f\"üí• All {max_retries} retries failed for {location}. It will be skipped.\")\n",
    "        self.failed_locations.append(location)\n",
    "\n",
    "    def run_collection_and_save(self) -> Tuple[bool, int]:\n",
    "        \"\"\"Main orchestration method.\"\"\"\n",
    "        logger.info(\"üöÄ Starting hourly weather data collection...\")\n",
    "        self.all_hourly_dataframes = []\n",
    "        self.failed_locations = []\n",
    "        \n",
    "        location_progress = tqdm(self.config.MONITORING_LOCATIONS.items(), desc=\"üåç Fetching Locations\", unit=\"location\")\n",
    "        for location, (lat, lon) in location_progress:\n",
    "            location_progress.set_postfix_str(f\"üìç {location}\")\n",
    "            self.fetch_for_location(location, lat, lon)\n",
    "\n",
    "        if not self.all_hourly_dataframes:\n",
    "            logger.error(\"No data was collected. Aborting save.\")\n",
    "            return False, 0\n",
    "        \n",
    "        # Combine all collected dataframes and save to a single CSV\n",
    "        try:\n",
    "            final_df = pd.concat(self.all_hourly_dataframes, ignore_index=True)\n",
    "            final_df.rename(columns={\n",
    "                'time': 'datetime',\n",
    "                'temperature_2m': 'temperature',\n",
    "                'relative_humidity_2m': 'humidity',\n",
    "                'precipitation': 'precipitation',\n",
    "                'surface_pressure': 'pressure',\n",
    "                'wind_speed_10m': 'wind_speed'\n",
    "            }, inplace=True)\n",
    "            \n",
    "            # Reorder columns for consistency\n",
    "            cols_order = ['location', 'datetime', 'temperature', 'humidity', 'precipitation', 'pressure', 'wind_speed']\n",
    "            final_df = final_df[cols_order]\n",
    "\n",
    "            final_df.to_csv(self.config.OUTPUT_CSV_PATH, index=False, encoding='utf-8')\n",
    "            total_records = len(final_df)\n",
    "            logger.info(f\"üíæ Combined and saved {total_records:,} hourly records to disk.\")\n",
    "            return not self.failed_locations, total_records\n",
    "        except Exception as e:\n",
    "            logger.critical(f\"üí• CRITICAL ERROR during final save: {e}\")\n",
    "            return False, 0\n",
    "\n",
    "# --- Initialize the collector ---\n",
    "collector = WeatherDataCollector(config)\n",
    "logger.info(\"üîß Hourly weather data collector class defined and instance created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7705841",
   "metadata": {},
   "source": [
    "## 4. Execute Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d64a313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:32:58,021 - INFO - üïê Collection started at: 2025-06-20 23:32:58\n",
      "2025-06-20 23:32:58,023 - INFO - üöÄ Starting hourly weather data collection...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d667efb87e4cc4a288cabf039d9950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üåç Fetching Locations:   0%|          | 0/23 [00:00<?, ?location/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:33:01,142 - INFO - ‚úÖ Fetched 36048 hourly records for Melbourne CBD.\n",
      "2025-06-20 23:33:02,656 - INFO - ‚úÖ Fetched 36048 hourly records for Footscray.\n",
      "2025-06-20 23:33:04,159 - INFO - ‚úÖ Fetched 36048 hourly records for Brooklyn.\n",
      "2025-06-20 23:33:06,926 - INFO - ‚úÖ Fetched 36048 hourly records for Alphington.\n",
      "2025-06-20 23:33:08,698 - INFO - ‚úÖ Fetched 36048 hourly records for Spotswood.\n",
      "2025-06-20 23:33:10,239 - INFO - ‚úÖ Fetched 36048 hourly records for Box Hill.\n",
      "2025-06-20 23:33:11,941 - INFO - ‚úÖ Fetched 36048 hourly records for Brighton.\n",
      "2025-06-20 23:33:13,533 - INFO - ‚úÖ Fetched 36048 hourly records for Dandenong.\n",
      "2025-06-20 23:33:15,009 - INFO - ‚úÖ Fetched 36048 hourly records for Mooroolbark.\n",
      "2025-06-20 23:33:16,514 - INFO - ‚úÖ Fetched 36048 hourly records for Altona North.\n",
      "2025-06-20 23:33:18,088 - INFO - ‚úÖ Fetched 36048 hourly records for Melton.\n",
      "2025-06-20 23:33:19,560 - INFO - ‚úÖ Fetched 36048 hourly records for Point Cook.\n",
      "2025-06-20 23:33:21,072 - INFO - ‚úÖ Fetched 36048 hourly records for Macleod.\n",
      "2025-06-20 23:33:21,321 - WARNING - üö¶ Rate limit for Carlton. Retrying in 5.8s... (Attempt 1/5)\n",
      "2025-06-20 23:33:27,364 - WARNING - üö¶ Rate limit for Carlton. Retrying in 10.6s... (Attempt 2/5)\n",
      "2025-06-20 23:33:38,165 - WARNING - üö¶ Rate limit for Carlton. Retrying in 20.4s... (Attempt 3/5)\n",
      "2025-06-20 23:33:58,776 - WARNING - üö¶ Rate limit for Carlton. Retrying in 40.8s... (Attempt 4/5)\n",
      "2025-06-20 23:34:41,230 - INFO - ‚úÖ Fetched 36048 hourly records for Carlton.\n",
      "2025-06-20 23:34:42,774 - INFO - ‚úÖ Fetched 36048 hourly records for Richmond.\n",
      "2025-06-20 23:34:44,319 - INFO - ‚úÖ Fetched 36048 hourly records for St Kilda.\n",
      "2025-06-20 23:34:45,823 - INFO - ‚úÖ Fetched 36048 hourly records for Yarraville.\n",
      "2025-06-20 23:34:47,767 - INFO - ‚úÖ Fetched 36048 hourly records for Frankston.\n",
      "2025-06-20 23:34:49,244 - INFO - ‚úÖ Fetched 36048 hourly records for Ringwood.\n",
      "2025-06-20 23:34:50,759 - INFO - ‚úÖ Fetched 36048 hourly records for Werribee.\n",
      "2025-06-20 23:34:52,382 - INFO - ‚úÖ Fetched 36048 hourly records for Craigieburn.\n",
      "2025-06-20 23:34:53,950 - INFO - ‚úÖ Fetched 36048 hourly records for Pakenham.\n",
      "2025-06-20 23:34:55,421 - INFO - ‚úÖ Fetched 36048 hourly records for Broadmeadows.\n",
      "2025-06-20 23:34:58,377 - INFO - üíæ Combined and saved 829,104 hourly records to disk.\n",
      "2025-06-20 23:34:58,388 - INFO - ============================================================\n",
      "2025-06-20 23:34:58,389 - INFO - ‚úÖ HOURLY DATA COLLECTION COMPLETED SUCCESSFULLY!\n",
      "2025-06-20 23:34:58,390 - INFO - üìÅ Data saved to: ../../data/raw/melbourne_raw_weather_openmeteo_2020-11-25_to_2025-01-04.csv\n",
      "2025-06-20 23:34:58,393 - INFO - üìä Total hourly records collected: 829,104\n",
      "2025-06-20 23:34:58,394 - INFO - ‚è±Ô∏è  Total duration: 0:02:00.365662\n",
      "2025-06-20 23:34:58,394 - INFO - üéØ Collection efficiency: 6888.21 records/second\n",
      "\n",
      "üéâ Raw hourly data is ready for the next processing step.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: DATA COLLECTION ORCHESTRATOR\n",
    "# =============================================================================\n",
    "\n",
    "def run_data_collection_pipeline():\n",
    "    logger.info(f\"üïê Collection started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    success, total_records = collector.run_collection_and_save()\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    logger.info(\"=\" * 60)\n",
    "    if success:\n",
    "        logger.info(\"‚úÖ HOURLY DATA COLLECTION COMPLETED SUCCESSFULLY!\")\n",
    "    else:\n",
    "        logger.warning(f\"‚ö†Ô∏è COLLECTION COMPLETED WITH ERRORS. Failed locations: {collector.failed_locations}\")\n",
    "    \n",
    "    logger.info(f\"üìÅ Data saved to: {config.OUTPUT_CSV_PATH}\")\n",
    "    logger.info(f\"üìä Total hourly records collected: {total_records:,}\")\n",
    "    logger.info(f\"‚è±Ô∏è  Total duration: {duration}\")\n",
    "    if duration.total_seconds() > 0:\n",
    "        logger.info(f\"üéØ Collection efficiency: {total_records / duration.total_seconds():.2f} records/second\")\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nüéâ Raw hourly data is ready for the next processing step.\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå DATA COLLECTION FAILED for some locations. Check logs for details.\")\n",
    "\n",
    "# --- Execute the Pipeline ---\n",
    "run_data_collection_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7754d",
   "metadata": {},
   "source": [
    "## 5. Data Validation (Quick Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cbc282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:36:41,000 - INFO - üìä Validating output file: '../../data/raw/melbourne_raw_weather_openmeteo_2020-11-25_to_2025-01-04.csv'...\n",
      "\n",
      "--- File Validation Report ---\n",
      "   - File shape (rows, columns): (829104, 7)\n",
      "   - Number of unique locations: 23\n",
      "\n",
      "Columns found:\n",
      "['location', 'datetime', 'temperature', 'humidity', 'precipitation', 'pressure', 'wind_speed']\n",
      "\n",
      "Data types:\n",
      "location          object\n",
      "datetime          object\n",
      "temperature      float64\n",
      "humidity           int64\n",
      "precipitation    float64\n",
      "pressure         float64\n",
      "wind_speed       float64\n",
      "dtype: object\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>datetime</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melbourne CBD</td>\n",
       "      <td>2020-11-25T00:00</td>\n",
       "      <td>15.1</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1010.9</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melbourne CBD</td>\n",
       "      <td>2020-11-25T01:00</td>\n",
       "      <td>14.1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1010.2</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melbourne CBD</td>\n",
       "      <td>2020-11-25T02:00</td>\n",
       "      <td>14.4</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melbourne CBD</td>\n",
       "      <td>2020-11-25T03:00</td>\n",
       "      <td>12.6</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Melbourne CBD</td>\n",
       "      <td>2020-11-25T04:00</td>\n",
       "      <td>11.7</td>\n",
       "      <td>99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        location          datetime  temperature  humidity  precipitation  \\\n",
       "0  Melbourne CBD  2020-11-25T00:00         15.1        87            0.0   \n",
       "1  Melbourne CBD  2020-11-25T01:00         14.1        90            0.0   \n",
       "2  Melbourne CBD  2020-11-25T02:00         14.4        90            0.0   \n",
       "3  Melbourne CBD  2020-11-25T03:00         12.6        97            0.0   \n",
       "4  Melbourne CBD  2020-11-25T04:00         11.7        99            0.0   \n",
       "\n",
       "   pressure  wind_speed  \n",
       "0    1010.9         4.2  \n",
       "1    1010.2         5.1  \n",
       "2    1009.8         0.4  \n",
       "3    1009.6         3.1  \n",
       "4    1009.5         4.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- End of Report ---\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: QUICK DATA VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "def validate_output_file():\n",
    "    \"\"\"Performs a quick check on the final output file.\"\"\"\n",
    "    if not os.path.exists(config.OUTPUT_CSV_PATH):\n",
    "        logger.error(f\"‚ùå No data file found at '{config.OUTPUT_CSV_PATH}'.\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"üìä Validating output file: '{config.OUTPUT_CSV_PATH}'...\")\n",
    "    try:\n",
    "        df = pd.read_csv(config.OUTPUT_CSV_PATH)\n",
    "        print(\"\\n--- File Validation Report ---\")\n",
    "        print(f\"   - File shape (rows, columns): {df.shape}\")\n",
    "        print(f\"   - Number of unique locations: {df['location'].nunique()}\")\n",
    "        print(f\"\\nColumns found:\")\n",
    "        print(df.columns.tolist())\n",
    "        print(\"\\nData types:\")\n",
    "        print(df.dtypes)\n",
    "        print(\"\\nSample data:\")\n",
    "        display(df.head())\n",
    "        print(\"--- End of Report ---\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Validation failed: {e}\")\n",
    "\n",
    "# --- Run the validation ---\n",
    "validate_output_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b836f31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
